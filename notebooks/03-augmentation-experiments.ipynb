{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation Experiments\n",
    "\n",
    "This notebook helps you:\n",
    "- Test different augmentation techniques\n",
    "- Compare augmentation strategies\n",
    "- Visualize augmentation effects\n",
    "- Optimize augmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from data_augmentation import AugmentedColorDataset, AugmentationVisualizer, create_augmented_dataset\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from utils import compare_images_side_by_side\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "config_path = \"../config/config.yaml\"\n",
    "aug_config_path = \"../config/augmentation_config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "with open(aug_config_path, 'r') as f:\n",
    "    aug_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Current augmentation strategy: {aug_config['current_strategy']}\")\n",
    "print(f\"Augmentation enabled: {aug_config['augmentation']['enabled']}\")\n",
    "\n",
    "# Check processed data\n",
    "processed_dir = \"../data/processed\"\n",
    "train_dir = os.path.join(processed_dir, \"train\")\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    print(\"\\n❌ Processed data not found!\")\n",
    "    print(\"Please run notebook 02_data_preprocessing.ipynb first.\")\n",
    "else:\n",
    "    image_count = len([f for f in os.listdir(train_dir) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    print(f\"\\n✓ Found {image_count} processed training images\")\n",
    "    \n",
    "    if image_count == 0:\n",
    "        print(\"No images found in processed directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preview Augmentation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available augmentation strategies\n",
    "print(\"Available Augmentation Strategies:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "strategies = aug_config['strategies']\n",
    "for strategy_name, strategy_config in strategies.items():\n",
    "    print(f\"\\n{strategy_name.upper()} Strategy:\")\n",
    "    print(f\"  Geometric probability: {strategy_config['geometric_prob']}\")\n",
    "    print(f\"  Photometric probability: {strategy_config['photometric_prob']}\")\n",
    "    print(f\"  Advanced probability: {strategy_config['advanced_prob']}\")\n",
    "\n",
    "# Show detailed augmentation settings\n",
    "print(\"\\nDetailed Augmentation Settings:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "aug_settings = aug_config['augmentation']\n",
    "print(f\"Overall probability: {aug_settings['probability']}\")\n",
    "\n",
    "print(\"\\nGeometric augmentations:\")\n",
    "for aug_name, aug_params in aug_settings['geometric'].items():\n",
    "    if aug_params['enabled']:\n",
    "        print(f\"  ✓ {aug_name}: p={aug_params['probability']}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {aug_name}: disabled\")\n",
    "\n",
    "print(\"\\nPhotometric augmentations:\")\n",
    "for aug_name, aug_params in aug_settings['photometric'].items():\n",
    "    if aug_params['enabled']:\n",
    "        print(f\"  ✓ {aug_name}: p={aug_params['probability']}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {aug_name}: disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Augmentation on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation visualizer\n",
    "if os.path.exists(train_dir) and len(os.listdir(train_dir)) > 0:\n",
    "    visualizer = AugmentationVisualizer(aug_config_path)\n",
    "    \n",
    "    # Get a sample image\n",
    "    sample_files = [f for f in os.listdir(train_dir) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if sample_files:\n",
    "        sample_image = os.path.join(train_dir, sample_files[0])\n",
    "        print(f\"Testing augmentation on: {sample_files[0]}\")\n",
    "        \n",
    "        # Preview augmentations\n",
    "        visualizer.preview_augmentations(\n",
    "            sample_image, \n",
    "            num_samples=6,\n",
    "            save_path=\"../results/augmentation_preview.png\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No sample images found for augmentation testing\")\n",
    "else:\n",
    "    print(\"No processed training data available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Different Augmentation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different augmentation strategies\n",
    "if os.path.exists(train_dir) and len(os.listdir(train_dir)) > 0:\n",
    "    \n",
    "    def test_strategy(strategy_name, sample_image_path):\n",
    "        \"\"\"Test a specific augmentation strategy.\"\"\"\n",
    "        # Temporarily modify config\n",
    "        original_strategy = aug_config['current_strategy']\n",
    "        aug_config['current_strategy'] = strategy_name\n",
    "        \n",
    "        # Save temporary config\n",
    "        temp_config_path = \"../config/temp_aug_config.yaml\"\n",
    "        with open(temp_config_path, 'w') as f:\n",
    "            yaml.dump(aug_config, f)\n",
    "        \n",
    "        # Create dataset with this strategy\n",
    "        dataset = AugmentedColorDataset(\n",
    "            os.path.dirname(sample_image_path),\n",
    "            temp_config_path,\n",
    "            is_training=True\n",
    "        )\n",
    "        \n",
    "        # Generate samples\n",
    "        filename = os.path.basename(sample_image_path)\n",
    "        try:\n",
    "            file_idx = dataset.image_files.index(filename)\n",
    "            samples = []\n",
    "            \n",
    "            for _ in range(3):\n",
    "                L, AB, _ = dataset[file_idx]\n",
    "                \n",
    "                # Convert back to RGB\n",
    "                preprocessor = DataPreprocessor()\n",
    "                L_denorm = (L + 1.0) / 2.0  # Denormalize\n",
    "                rgb_images = preprocessor.lab_to_rgb(\n",
    "                    L_denorm.unsqueeze(0), \n",
    "                    AB.unsqueeze(0)\n",
    "                )\n",
    "                samples.append(rgb_images[0])\n",
    "            \n",
    "            # Clean up\n",
    "            os.remove(temp_config_path)\n",
    "            aug_config['current_strategy'] = original_strategy\n",
    "            \n",
    "            return samples\n",
    "            \n",
    "        except (ValueError, IndexError) as e:\n",
    "            print(f\"Error testing strategy {strategy_name}: {e}\")\n",
    "            # Clean up\n",
    "            if os.path.exists(temp_config_path):\n",
    "                os.remove(temp_config_path)\n",
    "            aug_config['current_strategy'] = original_strategy\n",
    "            return []\n",
    "    \n",
    "    # Test all strategies on the same image\n",
    "    if sample_files:\n",
    "        sample_image = os.path.join(train_dir, sample_files[0])\n",
    "        \n",
    "        print(\"Comparing augmentation strategies...\")\n",
    "        \n",
    "        # Original image\n",
    "        original_img = Image.open(sample_image)\n",
    "        original_array = np.array(original_img) / 255.0\n",
    "        \n",
    "        fig, axes = plt.subplots(len(strategies) + 1, 4, figsize=(16, 4 * (len(strategies) + 1)))\n",
    "        \n",
    "        # Show original\n",
    "        axes[0, 0].imshow(original_array)\n",
    "        axes[0, 0].set_title('Original')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Hide unused original row plots\n",
    "        for i in range(1, 4):\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Test each strategy\n",
    "        for row, (strategy_name, _) in enumerate(strategies.items(), 1):\n",
    "            print(f\"Testing {strategy_name} strategy...\")\n",
    "            samples = test_strategy(strategy_name, sample_image)\n",
    "            \n",
    "            for col, sample in enumerate(samples[:3]):\n",
    "                axes[row, col].imshow(sample)\n",
    "                axes[row, col].set_title(f'{strategy_name.title()} #{col+1}')\n",
    "                axes[row, col].axis('off')\n",
    "            \n",
    "            # Hide unused column if less than 3 samples\n",
    "            for col in range(len(samples), 4):\n",
    "                axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results/strategy_comparison.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Strategy comparison saved to ../results/strategy_comparison.png\")\n",
    "\n",
    "else:\n",
    "    print(\"No processed data available for strategy testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Augmentation Effects on Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how augmentation affects dataset statistics\n",
    "if os.path.exists(train_dir) and len(os.listdir(train_dir)) > 0:\n",
    "    print(\"Analyzing augmentation effects on dataset statistics...\")\n",
    "    \n",
    "    # Create datasets with and without augmentation\n",
    "    print(\"Creating datasets for comparison...\")\n",
    "    \n",
    "    # Dataset without augmentation\n",
    "    temp_config = aug_config.copy()\n",
    "    temp_config['augmentation']['enabled'] = False\n",
    "    \n",
    "    temp_config_path = \"../config/no_aug_config.yaml\"\n",
    "    with open(temp_config_path, 'w') as f:\n",
    "        yaml.dump(temp_config, f)\n",
    "    \n",
    "    dataset_no_aug = AugmentedColorDataset(\n",
    "        train_dir,\n",
    "        temp_config_path,\n",
    "        is_training=False  # No augmentation\n",
    "    )\n",
    "    \n",
    "    # Dataset with augmentation\n",
    "    dataset_with_aug = AugmentedColorDataset(\n",
    "        train_dir,\n",
    "        aug_config_path,\n",
    "        is_training=True  # With augmentation\n",
    "    )\n",
    "    \n",
    "    # Collect statistics from both datasets\n",
    "    def collect_stats(dataset, num_samples=50):\n",
    "        \"\"\"Collect L and AB channel statistics.\"\"\"\n",
    "        L_values = []\n",
    "        AB_values = []\n",
    "        \n",
    "        sample_count = min(num_samples, len(dataset))\n",
    "        indices = np.random.choice(len(dataset), sample_count, replace=False)\n",
    "        \n",
    "        print(f\"Collecting statistics from {sample_count} samples...\")\n",
    "        \n",
    "        for idx in tqdm(indices):\n",
    "            try:\n",
    "                L, AB, _ = dataset[idx]\n",
    "                L_values.append(L.numpy().flatten())\n",
    "                AB_values.append(AB.numpy().flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {idx}: {e}\")\n",
    "        \n",
    "        if L_values and AB_values:\n",
    "            L_all = np.concatenate(L_values)\n",
    "            AB_all = np.concatenate(AB_values)\n",
    "            \n",
    "            return {\n",
    "                'L_mean': np.mean(L_all),\n",
    "                'L_std': np.std(L_all),\n",
    "                'L_min': np.min(L_all),\n",
    "                'L_max': np.max(L_all),\n",
    "                'AB_mean': np.mean(AB_all),\n",
    "                'AB_std': np.std(AB_all),\n",
    "                'AB_min': np.min(AB_all),\n",
    "                'AB_max': np.max(AB_all),\n",
    "                'L_values': L_all,\n",
    "                'AB_values': AB_all\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Collect statistics\n",
    "    print(\"\\nAnalyzing dataset without augmentation...\")\n",
    "    stats_no_aug = collect_stats(dataset_no_aug)\n",
    "    \n",
    "    print(\"\\nAnalyzing dataset with augmentation...\")\n",
    "    stats_with_aug = collect_stats(dataset_with_aug)\n",
    "    \n",
    "    # Clean up temp config\n",
    "    os.remove(temp_config_path)\n",
    "    \n",
    "    # Compare statistics\n",
    "    if stats_no_aug and stats_with_aug:\n",
    "        print(\"\\nStatistical Comparison:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"{'Metric':<15} {'No Aug':<10} {'With Aug':<10} {'Change':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        metrics = ['L_mean', 'L_std', 'AB_mean', 'AB_std']\n",
    "        for metric in metrics:\n",
    "            no_aug_val = stats_no_aug[metric]\n",
    "            with_aug_val = stats_with_aug[metric]\n",
    "            change = ((with_aug_val - no_aug_val) / no_aug_val) * 100\n",
    "            \n",
    "            print(f\"{metric:<15} {no_aug_val:<10.4f} {with_aug_val:<10.4f} {change:<+10.2f}%\")\n",
    "        \n",
    "        # Plot distributions\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        # L channel distribution\n",
    "        axes[0, 0].hist(stats_no_aug['L_values'][:10000], bins=50, alpha=0.7, \n",
    "                       label='No Augmentation', density=True)\n",
    "        axes[0, 0].hist(stats_with_aug['L_values'][:10000], bins=50, alpha=0.7, \n",
    "                       label='With Augmentation', density=True)\n",
    "        axes[0, 0].set_title('L Channel Distribution')\n",
    "        axes[0, 0].set_xlabel('L Value')\n",
    "        axes[0, 0].set_ylabel('Density')\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # AB channel distribution\n",
    "        axes[0, 1].hist(stats_no_aug['AB_values'][:10000], bins=50, alpha=0.7, \n",
    "                       label='No Augmentation', density=True)\n",
    "        axes[0, 1].hist(stats_with_aug['AB_values'][:10000], bins=50, alpha=0.7, \n",
    "                       label='With Augmentation', density=True)\n",
    "        axes[0, 1].set_title('AB Channels Distribution')\n",
    "        axes[0, 1].set_xlabel('AB Value')\n",
    "        axes[0, 1].set_ylabel('Density')\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # Box plots for better comparison\n",
    "        axes[1, 0].boxplot([stats_no_aug['L_values'][:5000], stats_with_aug['L_values'][:5000]], \n",
    "                          labels=['No Aug', 'With Aug'])\n",
    "        axes[1, 0].set_title('L Channel Box Plot')\n",
    "        axes[1, 0].set_ylabel('L Value')\n",
    "        \n",
    "        axes[1, 1].boxplot([stats_no_aug['AB_values'][:5000], stats_with_aug['AB_values'][:5000]], \n",
    "                          labels=['No Aug', 'With Aug'])\n",
    "        axes[1, 1].set_title('AB Channels Box Plot')\n",
    "        axes[1, 1].set_ylabel('AB Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results/augmentation_statistics.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nStatistical analysis saved to ../results/augmentation_statistics.png\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Could not collect statistics for comparison\")\n",
    "\n",
    "else:\n",
    "    print(\"No processed data available for statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Augmented Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small augmented dataset for experimentation\n",
    "if os.path.exists(train_dir) and len(os.listdir(train_dir)) > 0:\n",
    "    print(\"Creating augmented dataset samples...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    aug_sample_dir = \"../data/augmented_samples\"\n",
    "    os.makedirs(aug_sample_dir, exist_ok=True)\n",
    "    \n",
    "    # Select a few sample images\n",
    "    sample_files = [f for f in os.listdir(train_dir) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    num_samples = min(5, len(sample_files))\n",
    "    selected_samples = sample_files[:num_samples]\n",
    "    \n",
    "    print(f\"Creating augmented versions of {num_samples} images...\")\n",
    "    \n",
    "    # Create temporary directory with selected samples\n",
    "    temp_sample_dir = \"../data/temp_samples\"\n",
    "    os.makedirs(temp_sample_dir, exist_ok=True)\n",
    "    \n",
    "    for filename in selected_samples:\n",
    "        src = os.path.join(train_dir, filename)\n",
    "        dst = os.path.join(temp_sample_dir, filename)\n",
    "        import shutil\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    # Generate augmented versions\n",
    "    try:\n",
    "        create_augmented_dataset(\n",
    "            temp_sample_dir,\n",
    "            aug_sample_dir,\n",
    "            aug_config_path,\n",
    "            multiplier=3  # Create 3 augmented versions per image\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Augmented samples created in {aug_sample_dir}\")\n",
    "        \n",
    "        # Count results\n",
    "        total_images = len([f for f in os.listdir(aug_sample_dir) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\"Total images in augmented samples: {total_images}\")\n",
    "        print(f\"(Original: {num_samples}, Augmented: {total_images - num_samples})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating augmented dataset: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up temporary directory\n",
    "        if os.path.exists(temp_sample_dir):\n",
    "            shutil.rmtree(temp_sample_dir)\n",
    "\n",
    "else:\n",
    "    print(\"No processed data available for creating augmented samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide recommendations based on dataset size and analysis\n",
    "if os.path.exists(train_dir):\n",
    "    image_count = len([f for f in os.listdir(train_dir) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    \n",
    "    print(\"Augmentation Strategy Recommendations:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if image_count < 500:\n",
    "        print(\"📊 SMALL DATASET DETECTED\")\n",
    "        print(f\"You have {image_count} training images\")\n",
    "        print(\"\\n🔧 Recommendations:\")\n",
    "        print(\"• Use 'heavy' augmentation strategy\")\n",
    "        print(\"• Enable all geometric augmentations\")\n",
    "        print(\"• Use high probabilities (0.7-0.9)\")\n",
    "        print(\"• Consider advanced augmentations\")\n",
    "        print(\"• Create 5-8x more augmented images\")\n",
    "        \n",
    "        # Suggest config changes\n",
    "        print(\"\\n⚙️ Suggested config changes:\")\n",
    "        print(\"current_strategy: 'heavy'\")\n",
    "        print(\"augmentation.probability: 0.9\")\n",
    "        \n",
    "    elif image_count < 2000:\n",
    "        print(\"📊 MEDIUM DATASET DETECTED\")\n",
    "        print(f\"You have {image_count} training images\")\n",
    "        print(\"\\n🔧 Recommendations:\")\n",
    "        print(\"• Use 'medium' augmentation strategy\")\n",
    "        print(\"• Focus on geometric augmentations\")\n",
    "        print(\"• Use moderate probabilities (0.5-0.7)\")\n",
    "        print(\"• Create 3-4x more augmented images\")\n",
    "        \n",
    "        print(\"\\n⚙️ Suggested config changes:\")\n",
    "        print(\"current_strategy: 'medium'\")\n",
    "        print(\"augmentation.probability: 0.7\")\n",
    "        \n",
    "    else:\n",
    "        print(\"📊 LARGE DATASET DETECTED\")\n",
    "        print(f\"You have {image_count} training images\")\n",
    "        print(\"\\n🔧 Recommendations:\")\n",
    "        print(\"• Use 'light' augmentation strategy\")\n",
    "        print(\"• Focus on preserving image quality\")\n",
    "        print(\"• Use lower probabilities (0.3-0.5)\")\n",
    "        print(\"• Create 2x more augmented images\")\n",
    "        \n",
    "        print(\"\\n⚙️ Suggested config changes:\")\n",
    "        print(\"current_strategy: 'light'\")\n",
    "        print(\"augmentation.probability: 0.5\")\n",
    "    \n",
    "    print(\"\\n🎯 General Tips:\")\n",
    "    print(\"• Start with recommended strategy\")\n",
    "    print(\"• Monitor training loss for overfitting\")\n",
    "    print(\"• Reduce augmentation if loss becomes unstable\")\n",
    "    print(\"• Increase augmentation if model overfits quickly\")\n",
    "    \n",
    "    print(\"\\n📝 Next Steps:\")\n",
    "    print(\"1. Modify augmentation_config.yaml with recommendations\")\n",
    "    print(\"2. Run notebook 04_model_training_baseline.ipynb (no augmentation)\")\n",
    "    print(\"3. Run notebook 05_model_training_augmented.ipynb (with augmentation)\")\n",
    "    print(\"4. Compare results in notebook 06_evaluation_comparison.ipynb\")\n",
    "\n",
    "else:\n",
    "    print(\"No processed data found for providing recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment summary\n",
    "experiment_summary = {\n",
    "    'augmentation_experiments_completed': True,\n",
    "    'strategies_tested': list(strategies.keys()) if 'strategies' in locals() else [],\n",
    "    'current_strategy': aug_config['current_strategy'],\n",
    "    'dataset_size': image_count if 'image_count' in locals() else 0,\n",
    "    'augmentation_enabled': aug_config['augmentation']['enabled'],\n",
    "    'files_generated': [\n",
    "        'augmentation_preview.png',\n",
    "        'strategy_comparison.png',\n",
    "        'augmentation_statistics.png'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to results directory\n",
    "results_dir = \"../results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "summary_path = os.path.join(results_dir, 'augmentation_experiments.yaml')\n",
    "with open(summary_path, 'w') as f:\n",
    "    yaml.dump(experiment_summary, f, default_flow_style=False)\n",
    "\n",
    "print(\"Experiment Summary:\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in experiment_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n✓ Summary saved to: {summary_path}\")\n",
    "print(\"\\n🎉 Augmentation experiments completed!\")\n",
    "print(\"You're now ready to train models with different augmentation strategies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook helped you:\n",
    "\n",
    "✅ **Test Augmentation Techniques**: Visualized how different augmentations affect your images\n",
    "\n",
    "✅ **Compare Strategies**: Tested light, medium, and heavy augmentation approaches  \n",
    "\n",
    "✅ **Analyze Effects**: Measured how augmentation changes dataset statistics\n",
    "\n",
    "✅ **Get Recommendations**: Received tailored advice based on your dataset size\n",
    "\n",
    "### Key Findings:\n",
    "- **Current Strategy**: {aug_config['current_strategy'] if 'aug_config' in locals() else 'Unknown'}\n",
    "- **Dataset Size**: {image_count if 'image_count' in locals() else 'Unknown'} images\n",
    "- **Recommended Approach**: Based on dataset size analysis above\n",
    "\n",
    "### Next Steps:\n",
    "1. **Adjust Configuration**: Modify `config/augmentation_config.yaml` based on recommendations\n",
    "2. **Train Baseline**: Run `04_model_training_baseline.ipynb` without augmentation\n",
    "3. **Train Augmented**: Run `05_model_training_augmented.ipynb` with augmentation  \n",
    "4. **Compare Results**: Use `06_evaluation_comparison.ipynb` to see the improvement\n",
    "\n",
    "The goal is to find the right balance: enough augmentation to improve generalization, but not so much that it hurts image quality! 🎯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
