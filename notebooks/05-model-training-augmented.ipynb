{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Model Training (With Data Augmentation)\n",
    "\n",
    "This notebook trains a colorization model WITH data augmentation to improve performance and generalization.\n",
    "\n",
    "## Objectives:\n",
    "- Train U-Net model with augmented data\n",
    "- Compare against baseline performance\n",
    "- Demonstrate improvement from data augmentation\n",
    "- Save augmented model for final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from data_augmentation import AugmentedColorDataset\n",
    "from model_architecture import create_model, initialize_weights\n",
    "from training import ColorizationTrainer, train_model\n",
    "from evaluation import ColorizationEvaluator\n",
    "from utils import create_training_curves, save_experiment_config, log_gpu_usage\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    log_gpu_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "config_path = \"../config/config.yaml\"\n",
    "aug_config_path = \"../config/augmentation_config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "with open(aug_config_path, 'r') as f:\n",
    "    aug_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Augmented Training Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Model architecture: {config['model']['architecture']}\")\n",
    "print(f\"Input size: {config['data']['input_size']}\")\n",
    "print(f\"Batch size: {config['data']['batch_size']}\")\n",
    "print(f\"Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"Epochs: {config['training']['epochs']}\")\n",
    "print(f\"Augmentation enabled: {aug_config['augmentation']['enabled']}\")\n",
    "print(f\"Augmentation strategy: {aug_config['current_strategy']}\")\n",
    "print(f\"Augmentation probability: {aug_config['augmentation']['probability']}\")\n",
    "\n",
    "# Setup directories\n",
    "processed_dir = \"../data/processed\"\n",
    "train_dir = os.path.join(processed_dir, \"train\")\n",
    "val_dir = os.path.join(processed_dir, \"val\")\n",
    "test_dir = os.path.join(processed_dir, \"test\")\n",
    "\n",
    "augmented_model_dir = \"../models/augmented_model\"\n",
    "augmented_results_dir = \"../results/augmented\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(augmented_model_dir, exist_ok=True)\n",
    "os.makedirs(augmented_results_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nModel will be saved to: {augmented_model_dir}\")\n",
    "print(f\"Results will be saved to: {augmented_results_dir}\")\n",
    "\n",
    "# Check data availability\n",
    "def count_images(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    return len([f for f in os.listdir(directory) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "train_count = count_images(train_dir)\n",
    "val_count = count_images(val_dir)\n",
    "test_count = count_images(test_dir)\n",
    "\n",
    "print(f\"\\nDataset Status:\")\n",
    "print(f\"Training images: {train_count}\")\n",
    "print(f\"Validation images: {val_count}\")\n",
    "print(f\"Test images: {test_count}\")\n",
    "\n",
    "if train_count == 0:\n",
    "    print(\"\\nâŒ No training data found!\")\n",
    "    print(\"Please run notebook 02_data_preprocessing.ipynb first.\")\n",
    "    raise SystemExit(\"Training data required\")\n",
    "\n",
    "if val_count == 0:\n",
    "    print(\"\\nâš ï¸ No validation data found. Using training data for validation.\")\n",
    "    val_dir = train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Baseline Results for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline results if available\n",
    "baseline_history_path = \"../results/baseline/training_history.yaml\"\n",
    "baseline_eval_path = \"../results/baseline/quick_evaluation.yaml\"\n",
    "\n",
    "baseline_history = None\n",
    "baseline_eval = None\n",
    "\n",
    "if os.path.exists(baseline_history_path):\n",
    "    with open(baseline_history_path, 'r') as f:\n",
    "        baseline_history = yaml.safe_load(f)\n",
    "    print(f\"âœ“ Loaded baseline training history\")\n",
    "    print(f\"  Best baseline validation loss: {baseline_history['best_val_loss']:.4f}\")\n",
    "    print(f\"  Training duration: {baseline_history['training_duration_seconds']/60:.1f} minutes\")\n",
    "else:\n",
    "    print(\"âš ï¸ No baseline training history found\")\n",
    "    print(\"  Consider running notebook 04_model_training_baseline.ipynb first\")\n",
    "\n",
    "if os.path.exists(baseline_eval_path):\n",
    "    with open(baseline_eval_path, 'r') as f:\n",
    "        baseline_eval = yaml.safe_load(f)\n",
    "    print(f\"\\nâœ“ Loaded baseline evaluation results\")\n",
    "    print(f\"  Baseline PSNR: {baseline_eval['metrics']['psnr']:.2f} dB\")\n",
    "    print(f\"  Baseline SSIM: {baseline_eval['metrics']['ssim']:.4f}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No baseline evaluation found\")\n",
    "\n",
    "print(f\"\\nTarget: Beat baseline performance with augmented training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Augmented Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented datasets\n",
    "print(\"Creating augmented data loaders...\")\n",
    "\n",
    "try:\n",
    "    # Training dataset with augmentation\n",
    "    train_dataset = AugmentedColorDataset(\n",
    "        train_dir,\n",
    "        aug_config_path,\n",
    "        image_size=tuple(config['data']['input_size']),\n",
    "        is_training=True  # Enable augmentation\n",
    "    )\n",
    "    \n",
    "    # Validation dataset without augmentation\n",
    "    val_dataset = AugmentedColorDataset(\n",
    "        val_dir,\n",
    "        aug_config_path,\n",
    "        image_size=tuple(config['data']['input_size']),\n",
    "        is_training=False  # No augmentation for validation\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['data']['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['data']['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['data']['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['data']['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Augmented data loaders created successfully!\")\n",
    "    print(f\"  Train batches: {len(train_loader)} (with augmentation)\")\n",
    "    print(f\"  Val batches: {len(val_loader)} (no augmentation)\")\n",
    "    print(f\"  Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"  Val dataset size: {len(val_dataset)}\")\n",
    "    \n",
    "    # Test augmented data loading\n",
    "    print(\"\\nTesting augmented data loading...\")\n",
    "    for L, AB, filenames in train_loader:\n",
    "        print(f\"âœ“ Augmented batch loaded successfully:\")\n",
    "        print(f\"  L channel shape: {L.shape}\")\n",
    "        print(f\"  AB channels shape: {AB.shape}\")\n",
    "        print(f\"  Value ranges: L[{L.min():.3f}, {L.max():.3f}], AB[{AB.min():.3f}, {AB.max():.3f}]\")\n",
    "        break\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating augmented data loaders: {e}\")\n",
    "    # Fallback to regular data loaders\n",
    "    print(\"Falling back to regular data loaders...\")\n",
    "    \n",
    "    preprocessor = DataPreprocessor(config_path)\n",
    "    train_loader, val_loader, test_loader = preprocessor.create_dataloaders(\n",
    "        train_dir, val_dir, test_dir if test_count > 0 else None\n",
    "    )\n",
    "    print(\"âœ“ Regular data loaders created as fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Augmented Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of augmented data\n",
    "if 'train_dataset' in locals():\n",
    "    print(\"Visualizing augmented training samples...\")\n",
    "    \n",
    "    try:\n",
    "        # Get multiple augmented versions of the same image\n",
    "        sample_idx = 0\n",
    "        num_variations = 6\n",
    "        \n",
    "        fig, axes = plt.subplots(2, num_variations, figsize=(18, 8))\n",
    "        \n",
    "        for i in range(num_variations):\n",
    "            # Get augmented sample (each call may produce different augmentation)\n",
    "            L, AB, filename = train_dataset[sample_idx]\n",
    "            \n",
    "            # Convert back to RGB for visualization\n",
    "            from src.data_preprocessing import DataPreprocessor\n",
    "            preprocessor = DataPreprocessor()\n",
    "            \n",
    "            L_denorm = (L + 1.0) / 2.0  # Denormalize for conversion\n",
    "            rgb_image = preprocessor.lab_to_rgb(\n",
    "                L_denorm.unsqueeze(0), \n",
    "                AB.unsqueeze(0)\n",
    "            )[0]\n",
    "            \n",
    "            # Show color version\n",
    "            axes[0, i].imshow(rgb_image)\n",
    "            axes[0, i].set_title(f'Augmented {i+1}\\n(Color)', fontsize=10)\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Show grayscale input (what model sees)\n",
    "            L_display = L_denorm.squeeze().numpy()\n",
    "            axes[1, i].imshow(L_display, cmap='gray')\n",
    "            axes[1, i].set_title(f'Model Input {i+1}\\n(Grayscale)', fontsize=10)\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Augmented Variations of: {filename}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save augmentation examples\n",
    "        aug_examples_path = os.path.join(augmented_results_dir, 'augmentation_examples.png')\n",
    "        plt.savefig(aug_examples_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ“ Augmentation examples saved to: {aug_examples_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error visualizing augmented samples: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Augmented dataset not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create and Initialize Augmented Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented model (same architecture as baseline)\n",
    "print(\"Creating augmented model...\")\n",
    "\n",
    "try:\n",
    "    aug_model = create_model(config_path)\n",
    "    \n",
    "    # Initialize weights\n",
    "    initialize_weights(aug_model)\n",
    "    \n",
    "    # Print model information\n",
    "    num_params = aug_model.count_parameters()\n",
    "    model_size = aug_model.get_model_size()\n",
    "    \n",
    "    print(f\"âœ“ Augmented model created successfully!\")\n",
    "    print(f\"  Architecture: {aug_model.architecture}\")\n",
    "    print(f\"  Parameters: {num_params:,}\")\n",
    "    print(f\"  Model size: {model_size:.2f} MB\")\n",
    "    \n",
    "    # Compare with baseline if available\n",
    "    if baseline_history:\n",
    "        print(f\"\\nğŸ“Š Comparison with Baseline:\")\n",
    "        print(f\"  Same architecture: âœ“\")\n",
    "        print(f\"  Same parameters: âœ“\")\n",
    "        print(f\"  Difference: Training with augmented data\")\n",
    "        print(f\"  Target: Beat {baseline_history['best_val_loss']:.4f} validation loss\")\n",
    "    \n",
    "    # Move to device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    aug_model = aug_model.to(device)\n",
    "    print(f\"  Device: {device}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    dummy_input = torch.randn(1, 1, *config['data']['input_size']).to(device)\n",
    "    with torch.no_grad():\n",
    "        dummy_output = aug_model(dummy_input)\n",
    "    \n",
    "    print(f\"  Test forward pass: âœ“\")\n",
    "    print(f\"  Input shape: {dummy_input.shape}\")\n",
    "    print(f\"  Output shape: {dummy_output.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating augmented model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Augmented Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer for augmented model\n",
    "print(\"Setting up augmented training...\")\n",
    "\n",
    "try:\n",
    "    aug_trainer = ColorizationTrainer(\n",
    "        model=aug_model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        config_path=config_path\n",
    "    )\n",
    "    \n",
    "    print(\"âœ“ Augmented trainer initialized successfully!\")\n",
    "    print(f\"  Device: {aug_trainer.device}\")\n",
    "    print(f\"  Mixed precision: {aug_trainer.use_amp}\")\n",
    "    print(f\"  Optimizer: {type(aug_trainer.optimizer).__name__}\")\n",
    "    print(f\"  Scheduler: {type(aug_trainer.scheduler).__name__ if aug_trainer.scheduler else 'None'}\")\n",
    "    print(f\"  Loss function: {type(aug_trainer.criterion).__name__}\")\n",
    "    \n",
    "    # Log GPU usage\n",
    "    if torch.cuda.is_available():\n",
    "        log_gpu_usage()\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Training Strategy:\")\n",
    "    print(f\"  Augmentation: {aug_config['current_strategy']} strategy\")\n",
    "    print(f\"  Data variety: {len(train_dataset)} augmented samples per epoch\")\n",
    "    print(f\"  Expected improvement: Better generalization and robustness\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error setting up augmented training: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Start Augmented Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment configuration\n",
    "experiment_name = f\"augmented_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# Enhanced config with augmentation info\n",
    "enhanced_config = config.copy()\n",
    "enhanced_config['augmentation'] = aug_config\n",
    "enhanced_config['experiment_type'] = 'augmented'\n",
    "enhanced_config['baseline_comparison'] = baseline_history is not None\n",
    "\n",
    "save_experiment_config(enhanced_config, experiment_name, augmented_results_dir)\n",
    "\n",
    "print(f\"Starting augmented model training...\")\n",
    "print(f\"Experiment name: {experiment_name}\")\n",
    "print(f\"Results directory: {augmented_results_dir}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AUGMENTED TRAINING (WITH DATA AUGMENTATION)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Strategy: {aug_config['current_strategy']}\")\n",
    "print(f\"Augmentation probability: {aug_config['augmentation']['probability']}\")\n",
    "\n",
    "if baseline_history:\n",
    "    print(f\"ğŸ¯ Target: Beat baseline validation loss of {baseline_history['best_val_loss']:.4f}\")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "try:\n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the augmented model\n",
    "    aug_history = aug_trainer.train()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nğŸ‰ AUGMENTED TRAINING COMPLETED!\")\n",
    "    print(f\"Training time: {training_duration:.2f} seconds ({training_duration/60:.1f} minutes)\")\n",
    "    print(f\"Best validation loss: {aug_history['best_val_loss']:.4f}\")\n",
    "    print(f\"Final training loss: {aug_history['train_losses'][-1]:.4f}\")\n",
    "    print(f\"Final validation loss: {aug_history['val_losses'][-1]:.4f}\")\n",
    "    \n",
    "    # Compare with baseline\n",
    "    if baseline_history:\n",
    "        improvement = baseline_history['best_val_loss'] - aug_history['best_val_loss']\n",
    "        improvement_percent = (improvement / baseline_history['best_val_loss']) * 100\n",
    "        \n",
    "        print(f\"\\nğŸ“Š COMPARISON WITH BASELINE:\")\n",
    "        print(f\"  Baseline best val loss: {baseline_history['best_val_loss']:.4f}\")\n",
    "        print(f\"  Augmented best val loss: {aug_history['best_val_loss']:.4f}\")\n",
    "        print(f\"  Improvement: {improvement:.4f} ({improvement_percent:+.2f}%)\")\n",
    "        \n",
    "        if improvement > 0:\n",
    "            print(f\"  âœ… AUGMENTATION SUCCESSFUL! Model improved!\")\n",
    "        elif improvement > -0.01:\n",
    "            print(f\"  â– Similar performance (within margin)\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸  Augmented model performed worse - may need tuning\")\n",
    "    \n",
    "    # Save training history\n",
    "    aug_history_data = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'experiment_type': 'augmented',\n",
    "        'augmentation_strategy': aug_config['current_strategy'],\n",
    "        'augmentation_probability': aug_config['augmentation']['probability'],\n",
    "        'training_duration_seconds': training_duration,\n",
    "        'best_val_loss': float(aug_history['best_val_loss']),\n",
    "        'final_train_loss': float(aug_history['train_losses'][-1]),\n",
    "        'final_val_loss': float(aug_history['val_losses'][-1]),\n",
    "        'total_epochs': len(aug_history['train_losses']),\n",
    "        'train_losses': [float(x) for x in aug_history['train_losses']],\n",
    "        'val_losses': [float(x) for x in aug_history['val_losses']]\n",
    "    }\n",
    "    \n",
    "    if baseline_history:\n",
    "        aug_history_data['baseline_comparison'] = {\n",
    "            'baseline_best_val_loss': baseline_history['best_val_loss'],\n",
    "            'improvement': float(improvement),\n",
    "            'improvement_percent': float(improvement_percent)\n",
    "        }\n",
    "    \n",
    "    history_path = os.path.join(augmented_results_dir, 'training_history.yaml')\n",
    "    with open(history_path, 'w') as f:\n",
    "        yaml.dump(aug_history_data, f)\n",
    "    \n",
    "    print(f\"\\nâœ“ Augmented training history saved to: {history_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Augmented training failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Augmented Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained augmented model\n",
    "if 'aug_history' in locals():\n",
    "    print(\"Saving augmented model...\")\n",
    "    \n",
    "    try:\n",
    "        # Save complete model state\n",
    "        model_save_path = os.path.join(augmented_model_dir, 'augmented_model_complete.pth')\n",
    "        torch.save({\n",
    "            'model_state_dict': aug_model.state_dict(),\n",
    "            'model_architecture': config['model']['architecture'],\n",
    "            'model_config': config['model'],\n",
    "            'training_config': config['training'],\n",
    "            'data_config': config['data'],\n",
    "            'augmentation_config': aug_config,\n",
    "            'training_history': aug_history,\n",
    "            'experiment_name': experiment_name,\n",
    "            'total_parameters': aug_model.count_parameters(),\n",
    "            'model_size_mb': aug_model.get_model_size(),\n",
    "            'augmentation_strategy': aug_config['current_strategy']\n",
    "        }, model_save_path)\n",
    "        \n",
    "        # Save just the model weights\n",
    "        weights_save_path = os.path.join(augmented_model_dir, 'augmented_weights.pth')\n",
    "        torch.save(aug_model.state_dict(), weights_save_path)\n",
    "        \n",
    "        print(f\"âœ“ Complete augmented model saved to: {model_save_path}\")\n",
    "        print(f\"âœ“ Augmented model weights saved to: {weights_save_path}\")\n",
    "        \n",
    "        # Create model info file\n",
    "        model_info = {\n",
    "            'model_name': 'Augmented Colorization Model',\n",
    "            'architecture': config['model']['architecture'],\n",
    "            'input_channels': config['model']['input_channels'],\n",
    "            'output_channels': config['model']['output_channels'],\n",
    "            'total_parameters': aug_model.count_parameters(),\n",
    "            'model_size_mb': aug_model.get_model_size(),\n",
    "            'training_data_augmented': True,\n",
    "            'augmentation_strategy': aug_config['current_strategy'],\n",
    "            'augmentation_probability': aug_config['augmentation']['probability'],\n",
    "            'best_validation_loss': float(aug_history['best_val_loss']),\n",
    "            'training_epochs': len(aug_history['train_losses']),\n",
    "            'training_duration_minutes': training_duration / 60,\n",
    "            'created_date': datetime.now().isoformat(),\n",
    "            'files': {\n",
    "                'complete_model': 'augmented_model_complete.pth',\n",
    "                'weights_only': 'augmented_weights.pth',\n",
    "                'training_history': '../results/augmented/training_history.yaml'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add baseline comparison if available\n",
    "        if baseline_history:\n",
    "            improvement = baseline_history['best_val_loss'] - aug_history['best_val_loss']\n",
    "            model_info['baseline_comparison'] = {\n",
    "                'baseline_val_loss': baseline_history['best_val_loss'],\n",
    "                'improvement': float(improvement),\n",
    "                'improvement_percent': float((improvement / baseline_history['best_val_loss']) * 100)\n",
    "            }\n",
    "        \n",
    "        info_path = os.path.join(augmented_model_dir, 'model_info.yaml')\n",
    "        with open(info_path, 'w') as f:\n",
    "            yaml.dump(model_info, f, default_flow_style=False)\n",
    "        \n",
    "        print(f\"âœ“ Augmented model info saved to: {info_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving augmented model: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No augmented training history available - model not saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Training Curves and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training curves and comparison\n",
    "if 'aug_history' in locals():\n",
    "    print(\"Generating augmented training curves and comparison...\")\n",
    "    \n",
    "    try:\n",
    "        # Create augmented training curves\n",
    "        aug_curves_path = os.path.join(augmented_results_dir, 'training_curves.png')\n",
    "        create_training_curves(\n",
    "            aug_history['train_losses'],\n",
    "            aug_history['val_losses'],\n",
    "            save_path=aug_curves_path,\n",
    "            title=\"Augmented Model Training Curves (With Data Augmentation)\"\n",
    "        )\n",
    "        print(f\"âœ“ Augmented training curves saved to: {aug_curves_path}\")\n",
    "        \n",
    "        # Create comparison plot if baseline is available\n",
    "        if baseline_history:\n",
    "            print(\"\\nCreating baseline vs augmented comparison...\")\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Training loss comparison\n",
    "            baseline_epochs = range(1, len(baseline_history['train_losses']) + 1)\n",
    "            aug_epochs = range(1, len(aug_history['train_losses']) + 1)\n",
    "            \n",
    "            axes[0].plot(baseline_epochs, baseline_history['train_losses'], \n",
    "                        'b-', label='Baseline (No Augmentation)', linewidth=2)\n",
    "            axes[0].plot(aug_epochs, aug_history['train_losses'], \n",
    "                        'r-', label='Augmented (With Augmentation)', linewidth=2)\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Training Loss')\n",
    "            axes[0].set_title('Training Loss Comparison')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Validation loss comparison\n",
    "            axes[1].plot(baseline_epochs, baseline_history['val_losses'], \n",
    "                        'b-', label='Baseline (No Augmentation)', linewidth=2)\n",
    "            axes[1].plot(aug_epochs, aug_history['val_losses'], \n",
    "                        'r-', label='Augmented (With Augmentation)', linewidth=2)\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Validation Loss')\n",
    "            axes[1].set_title('Validation Loss Comparison')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add best loss annotations\n",
    "            baseline_best_epoch = np.argmin(baseline_history['val_losses']) + 1\n",
    "            aug_best_epoch = np.argmin(aug_history['val_losses']) + 1\n",
    "            \n",
    "            axes[1].scatter(baseline_best_epoch, baseline_history['best_val_loss'], \n",
    "                           color='blue', s=100, zorder=5)\n",
    "            axes[1].scatter(aug_best_epoch, aug_history['best_val_loss'], \n",
    "                           color='red', s=100, zorder=5)\n",
    "            \n",
    "            axes[1].annotate(f'Baseline Best: {baseline_history[\"best_val_loss\"]:.4f}',\n",
    "                            xy=(baseline_best_epoch, baseline_history['best_val_loss']),\n",
    "                            xytext=(10, 10), textcoords='offset points',\n",
    "                            bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "            \n",
    "            axes[1].annotate(f'Augmented Best: {aug_history[\"best_val_loss\"]:.4f}',\n",
    "                            xy=(aug_best_epoch, aug_history['best_val_loss']),\n",
    "                            xytext=(10, -20), textcoords='offset points',\n",
    "                            bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save comparison\n",
    "            comparison_path = os.path.join(augmented_results_dir, 'baseline_vs_augmented_curves.png')\n",
    "            plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"âœ“ Baseline vs Augmented comparison saved to: {comparison_path}\")\n",
    "        \n",
    "        # Display comprehensive statistics\n",
    "        print(\"\\nAugmented Training Statistics:\")\n",
    "        print(\"=\" * 45)\n",
    "        print(f\"Total epochs: {len(aug_history['train_losses'])}\")\n",
    "        print(f\"Best validation loss: {aug_history['best_val_loss']:.4f}\")\n",
    "        print(f\"Final training loss: {aug_history['train_losses'][-1]:.4f}\")\n",
    "        print(f\"Final validation loss: {aug_history['val_losses'][-1]:.4f}\")\n",
    "        print(f\"Training time: {training_duration/60:.1f} minutes\")\n",
    "        print(f\"Augmentation strategy: {aug_config['current_strategy']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating curves and comparison: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No augmented training history available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quick Evaluation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quick evaluation on augmented model\n",
    "if 'aug_model' in locals() and 'val_loader' in locals():\n",
    "    print(\"Performing quick augmented model evaluation...\")\n",
    "    \n",
    "    try:\n",
    "        evaluator = ColorizationEvaluator(config_path)\n",
    "        \n",
    "        # Quick evaluation on subset\n",
    "        quick_metrics = {'psnr': [], 'ssim': [], 'mse': [], 'mae': []}\n",
    "        samples_evaluated = 0\n",
    "        max_samples = 50\n",
    "        \n",
    "        aug_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (L, AB, filenames) in enumerate(val_loader):\n",
    "                if samples_evaluated >= max_samples:\n",
    "                    break\n",
    "                    \n",
    "                batch_metrics = evaluator.evaluate_batch(aug_model, L, AB, filenames)\n",
    "                \n",
    "                for key in quick_metrics:\n",
    "                    quick_metrics[key].append(batch_metrics[key])\n",
    "                \n",
    "                samples_evaluated += len(filenames)\n",
    "        \n",
    "        # Calculate averages\n",
    "        avg_metrics = {key: np.mean(values) for key, values in quick_metrics.items()}\n",
    "        \n",
    "        print(f\"\\nAugmented Model Quick Evaluation:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Samples evaluated: {samples_evaluated}\")\n",
    "        print(f\"PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "        print(f\"SSIM: {avg_metrics['ssim']:.4f}\")\n",
    "        print(f\"MSE: {avg_metrics['mse']:.6f}\")\n",
    "        print(f\"MAE: {avg_metrics['mae']:.6f}\")\n",
    "        \n",
    "        # Compare with baseline evaluation\n",
    "        if baseline_eval:\n",
    "            print(f\"\\nğŸ“Š Evaluation Comparison with Baseline:\")\n",
    "            print(\"=\" * 45)\n",
    "            \n",
    "            metrics_comparison = {\n",
    "                'PSNR (dB)': (baseline_eval['metrics']['psnr'], avg_metrics['psnr']),\n",
    "                'SSIM': (baseline_eval['metrics']['ssim'], avg_metrics['ssim']),\n",
    "                'MSE': (baseline_eval['metrics']['mse'], avg_metrics['mse']),\n",
    "                'MAE': (baseline_eval['metrics']['mae'], avg_metrics['mae'])\n",
    "            }\n",
    "            \n",
    "            for metric_name, (baseline_val, aug_val) in metrics_comparison.items():\n",
    "                if metric_name in ['PSNR (dB)', 'SSIM']:  # Higher is better\n",
    "                    improvement = aug_val - baseline_val\n",
    "                    improvement_pct = (improvement / baseline_val) * 100\n",
    "                else:  # Lower is better (MSE, MAE)\n",
    "                    improvement = baseline_val - aug_val\n",
    "                    improvement_pct = (improvement / baseline_val) * 100\n",
    "                \n",
    "                status = \"âœ…\" if improvement > 0 else \"âŒ\" if improvement < -0.001 else \"â–\"\n",
    "                print(f\"  {metric_name:<10}: Baseline={baseline_val:.4f}, Augmented={aug_val:.4f} ({improvement_pct:+.2f}%) {status}\")\n",
    "        \n",
    "        # Save evaluation results\n",
    "        eval_results = {\n",
    "            'model_type': 'augmented',\n",
    "            'augmentation_used': True,\n",
    "            'augmentation_strategy': aug_config['current_strategy'],\n",
    "            'samples_evaluated': samples_evaluated,\n",
    "            'quick_evaluation': True,\n",
    "            'metrics': avg_metrics,\n",
    "            'evaluation_date': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        if baseline_eval:\n",
    "            eval_results['baseline_comparison'] = {\n",
    "                'baseline_metrics': baseline_eval['metrics'],\n",
    "                'improvements': {\n",
    "                    'psnr_improvement': avg_metrics['psnr'] - baseline_eval['metrics']['psnr'],\n",
    "                    'ssim_improvement': avg_metrics['ssim'] - baseline_eval['metrics']['ssim'],\n",
    "                    'mse_improvement': baseline_eval['metrics']['mse'] - avg_metrics['mse'],\n",
    "                    'mae_improvement': baseline_eval['metrics']['mae'] - avg_metrics['mae']\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        eval_path = os.path.join(augmented_results_dir, 'quick_evaluation.yaml')\n",
    "        with open(eval_path, 'w') as f:\n",
    "            yaml.dump(eval_results, f, default_flow_style=False)\n",
    "        \n",
    "        print(f\"\\nâœ“ Augmented evaluation results saved to: {eval_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during augmented evaluation: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Augmented model or validation data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive summary\n",
    "print(\"AUGMENTED TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'aug_history' in locals():\n",
    "    print(f\"âœ… Augmented Training Status: COMPLETED\")\n",
    "    print(f\"ğŸ“Š Best Validation Loss: {aug_history['best_val_loss']:.4f}\")\n",
    "    print(f\"â±ï¸  Training Duration: {training_duration/60:.1f} minutes\")\n",
    "    print(f\"ğŸ¨ Augmentation Strategy: {aug_config['current_strategy']}\")\n",
    "    print(f\"ğŸ”„ Augmentation Probability: {aug_config['augmentation']['probability']}\")\n",
    "    \n",
    "    if baseline_history:\n",
    "        improvement = baseline_history['best_val_loss'] - aug_history['best_val_loss']\n",
    "        improvement_percent = (improvement / baseline_history['best_val_loss']) * 100\n",
    "        \n",
    "        print(f\"\\nğŸ†š BASELINE COMPARISON:\")\n",
    "        print(f\"  Baseline Loss: {baseline_history['best_val_loss']:.4f}\")\n",
    "        print(f\"  Augmented Loss: {aug_history['best_val_loss']:.4f}\")\n",
    "        print(f\"  Improvement: {improvement:.4f} ({improvement_percent:+.2f}%)\")\n",
    "        \n",
    "        if improvement > 0.001:\n",
    "            print(f\"  ğŸ‰ SUCCESS: Augmentation significantly improved the model!\")\n",
    "        elif improvement > -0.001:\n",
    "            print(f\"  â– SIMILAR: Performance is comparable (within margin)\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸  REGRESSION: Augmented model performed worse\")\n",
    "            print(f\"     Consider: different augmentation strategy or hyperparameters\")\n",
    "    \n",
    "    if 'avg_metrics' in locals():\n",
    "        print(f\"\\nğŸ“ˆ Quick Evaluation Metrics:\")\n",
    "        print(f\"   PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "        print(f\"   SSIM: {avg_metrics['ssim']:.4f}\")\n",
    "        \n",
    "        if baseline_eval:\n",
    "            psnr_imp = avg_metrics['psnr'] - baseline_eval['metrics']['psnr']\n",
    "            ssim_imp = avg_metrics['ssim'] - baseline_eval['metrics']['ssim']\n",
    "            print(f\"   PSNR improvement: {psnr_imp:+.2f} dB\")\n",
    "            print(f\"   SSIM improvement: {ssim_imp:+.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Augmented Training Status: NOT COMPLETED\")\n",
    "\n",
    "print(f\"\\nğŸ“ Files Generated:\")\n",
    "generated_files = [\n",
    "    \"models/augmented_model/augmented_model_complete.pth\",\n",
    "    \"models/augmented_model/augmented_weights.pth\",\n",
    "    \"models/augmented_model/model_info.yaml\",\n",
    "    \"results/augmented/training_history.yaml\",\n",
    "    \"results/augmented/training_curves.png\",\n",
    "    \"results/augmented/baseline_vs_augmented_curves.png\",\n",
    "    \"results/augmented/quick_evaluation.yaml\",\n",
    "    \"results/augmented/augmentation_examples.png\"\n",
    "]\n",
    "\n",
    "for file in generated_files:\n",
    "    file_path = f\"../{file}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"   âœ… {file}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {file} (not created)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Next Steps:\")\n",
    "print(f\"1. âœ… Augmented model training completed\")\n",
    "print(f\"2. ğŸ“Š Run notebook 06_evaluation_comparison.ipynb for detailed comparison\")\n",
    "print(f\"3. ğŸ–¥ï¸  Use notebook 07_gui_demo.ipynb to test both models interactively\")\n",
    "print(f\"4. ğŸ“ Consider further experiments with different augmentation strategies\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Key Findings:\")\n",
    "if 'aug_history' in locals() and baseline_history:\n",
    "    if improvement > 0.001:\n",
    "        print(f\"   ğŸ‰ Data augmentation successfully improved model performance!\")\n",
    "        print(f\"   ğŸ“ˆ This demonstrates the value of diverse training data\")\n",
    "        print(f\"   ğŸ”§ The '{aug_config['current_strategy']}' strategy worked well for your dataset\")\n",
    "    elif improvement > -0.001:\n",
    "        print(f\"   ğŸ¤” Augmentation didn't significantly change performance\")\n",
    "        print(f\"   ğŸ’­ Possible reasons: dataset already diverse, or need different augmentation\")\n",
    "        print(f\"   ğŸ”§ Try adjusting augmentation strategy or parameters\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  Augmentation decreased performance\")\n",
    "        print(f\"   ğŸ”§ Try reducing augmentation intensity or different techniques\")\n",
    "        print(f\"   ğŸ“Š The baseline model may have been sufficient for this dataset\")\n",
    "else:\n",
    "    print(f\"   ğŸ“Š Complete both baseline and augmented training to compare results\")\n",
    "    \n",
    "print(f\"\\nğŸ Augmented training phase complete! Ready for comprehensive evaluation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
