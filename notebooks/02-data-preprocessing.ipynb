{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Image Colorization\n",
    "\n",
    "This notebook handles:\n",
    "- Converting RGB images to LAB color space\n",
    "- Creating train/validation/test splits\n",
    "- Preprocessing images for model training\n",
    "- Saving processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from skimage import color\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from data_preprocessing import DataPreprocessor, ColorDataset, split_dataset\n",
    "from utils import create_dataset_splits, setup_project_directories\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../config/config.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Input size: {config['data']['input_size']}\")\n",
    "print(f\"Batch size: {config['data']['batch_size']}\")\n",
    "print(f\"Color space: {config['data']['color_space']}\")\n",
    "\n",
    "# Setup directories\n",
    "data_root = \"../data\"\n",
    "raw_dir = os.path.join(data_root, \"raw\")\n",
    "processed_dir = os.path.join(data_root, \"processed\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(processed_dir, split), exist_ok=True)\n",
    "\n",
    "print(f\"Raw data directory: {raw_dir}\")\n",
    "print(f\"Processed data directory: {processed_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we need to create splits\n",
    "raw_train_dir = os.path.join(raw_dir, \"train\")\n",
    "raw_val_dir = os.path.join(raw_dir, \"val\")\n",
    "raw_test_dir = os.path.join(raw_dir, \"test\")\n",
    "\n",
    "# Count existing images\n",
    "def count_images(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    return len([f for f in os.listdir(directory) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))])\n",
    "\n",
    "train_count = count_images(raw_train_dir)\n",
    "val_count = count_images(raw_val_dir)\n",
    "test_count = count_images(raw_test_dir)\n",
    "\n",
    "print(f\"Current raw data counts:\")\n",
    "print(f\"Train: {train_count}\")\n",
    "print(f\"Val: {val_count}\")\n",
    "print(f\"Test: {test_count}\")\n",
    "\n",
    "# If no splits exist, create them from a single directory\n",
    "if train_count == 0 and val_count == 0 and test_count == 0:\n",
    "    # Check if there are images directly in raw directory\n",
    "    raw_images = count_images(raw_dir)\n",
    "    if raw_images > 0:\n",
    "        print(f\"\\nFound {raw_images} images in raw directory. Creating splits...\")\n",
    "        \n",
    "        # Create splits\n",
    "        split_info = create_dataset_splits(\n",
    "            raw_dir,\n",
    "            raw_dir,  # Output to same directory structure\n",
    "            train_ratio=config['data']['train_split'],\n",
    "            val_ratio=config['data']['val_split'],\n",
    "            test_ratio=config['data']['test_split']\n",
    "        )\n",
    "        \n",
    "        print(\"Dataset splits created successfully!\")\n",
    "        print(split_info)\n",
    "    else:\n",
    "        print(\"\\n⚠️  No images found in raw directory!\")\n",
    "        print(\"Please add images to ../data/raw/ first.\")\n",
    "        print(\"You can:\")\n",
    "        print(\"1. Copy images directly to ../data/raw/\")\n",
    "        print(\"2. Or create train/val/test subdirectories manually\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preview Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample raw images\n",
    "def show_raw_samples(directory, num_samples=4):\n",
    "    \"\"\"Display sample images from raw directory.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory {directory} does not exist\")\n",
    "        return\n",
    "    \n",
    "    image_files = [f for f in os.listdir(directory) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"No images found in {directory}\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    selected_files = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, len(selected_files), figsize=(15, 8))\n",
    "    if len(selected_files) == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    for i, filename in enumerate(selected_files):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load original image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Show original\n",
    "            axes[0, i].imshow(img_array)\n",
    "            axes[0, i].set_title(f'Original\\n{filename}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Show grayscale version (what model will see as input)\n",
    "            gray_img = img.convert('L')\n",
    "            axes[1, i].imshow(gray_img, cmap='gray')\n",
    "            axes[1, i].set_title(f'Grayscale (Input)')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show samples from training data\n",
    "if train_count > 0:\n",
    "    print(\"Sample Training Images:\")\n",
    "    show_raw_samples(raw_train_dir)\n",
    "else:\n",
    "    print(\"No training images to preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LAB Color Space Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate LAB color space conversion\n",
    "def demo_lab_conversion(image_path):\n",
    "    \"\"\"Demonstrate LAB color space conversion.\"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((256, 256))  # Resize for consistency\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Convert to LAB\n",
    "    lab_image = color.rgb2lab(img_array)\n",
    "    \n",
    "    # Extract channels\n",
    "    L = lab_image[:, :, 0]  # Lightness\n",
    "    A = lab_image[:, :, 1]  # Green-Red\n",
    "    B = lab_image[:, :, 2]  # Blue-Yellow\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Original\n",
    "    axes[0, 0].imshow(img_array)\n",
    "    axes[0, 0].set_title('Original RGB')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # L channel\n",
    "    axes[0, 1].imshow(L, cmap='gray')\n",
    "    axes[0, 1].set_title('L Channel (Lightness)\\nModel Input')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Grayscale comparison\n",
    "    gray_simple = color.rgb2gray(img_array)\n",
    "    axes[0, 2].imshow(gray_simple, cmap='gray')\n",
    "    axes[0, 2].set_title('RGB to Gray (comparison)')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # A channel\n",
    "    axes[1, 0].imshow(A, cmap='RdYlGn_r')\n",
    "    axes[1, 0].set_title('A Channel (Green-Red)\\nModel Output')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # B channel\n",
    "    axes[1, 1].imshow(B, cmap='YlGnBu_r')\n",
    "    axes[1, 1].set_title('B Channel (Blue-Yellow)\\nModel Output')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Reconstructed\n",
    "    reconstructed = color.lab2rgb(lab_image)\n",
    "    axes[1, 2].imshow(reconstructed)\n",
    "    axes[1, 2].set_title('Reconstructed RGB')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"L channel range: {L.min():.1f} to {L.max():.1f}\")\n",
    "    print(f\"A channel range: {A.min():.1f} to {A.max():.1f}\")\n",
    "    print(f\"B channel range: {B.min():.1f} to {B.max():.1f}\")\n",
    "\n",
    "# Demo LAB conversion if we have images\n",
    "if train_count > 0:\n",
    "    sample_image = None\n",
    "    for filename in os.listdir(raw_train_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            sample_image = os.path.join(raw_train_dir, filename)\n",
    "            break\n",
    "    \n",
    "    if sample_image:\n",
    "        print(\"LAB Color Space Conversion Demo:\")\n",
    "        demo_lab_conversion(sample_image)\n",
    "else:\n",
    "    print(\"No images available for LAB conversion demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and copy images to processed directory\n",
    "def process_dataset(input_dir, output_dir, target_size=(256, 256)):\n",
    "    \"\"\"Process raw images and save to processed directory.\"\"\"\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist\")\n",
    "        return 0\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"No images found in {input_dir}\")\n",
    "        return 0\n",
    "    \n",
    "    processed_count = 0\n",
    "    errors = []\n",
    "    \n",
    "    print(f\"Processing {len(image_files)} images from {input_dir}...\")\n",
    "    \n",
    "    for filename in tqdm(image_files):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            with Image.open(input_path) as img:\n",
    "                # Convert to RGB if necessary\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Resize to target size\n",
    "                img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Save processed image\n",
    "                img.save(output_path, 'PNG')  # Save as PNG to avoid compression artifacts\n",
    "                \n",
    "                processed_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors.append((filename, str(e)))\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully processed {processed_count} images\")\n",
    "    if errors:\n",
    "        print(f\"Failed to process {len(errors)} images\")\n",
    "    \n",
    "    return processed_count\n",
    "\n",
    "# Process all splits\n",
    "target_size = tuple(config['data']['input_size'])\n",
    "print(f\"Target image size: {target_size}\")\n",
    "\n",
    "total_processed = 0\n",
    "\n",
    "# Process train\n",
    "if train_count > 0:\n",
    "    train_processed = process_dataset(\n",
    "        raw_train_dir, \n",
    "        os.path.join(processed_dir, 'train'), \n",
    "        target_size\n",
    "    )\n",
    "    total_processed += train_processed\n",
    "\n",
    "# Process validation\n",
    "if val_count > 0:\n",
    "    val_processed = process_dataset(\n",
    "        raw_val_dir, \n",
    "        os.path.join(processed_dir, 'val'), \n",
    "        target_size\n",
    "    )\n",
    "    total_processed += val_processed\n",
    "\n",
    "# Process test\n",
    "if test_count > 0:\n",
    "    test_processed = process_dataset(\n",
    "        raw_test_dir, \n",
    "        os.path.join(processed_dir, 'test'), \n",
    "        target_size\n",
    "    )\n",
    "    total_processed += test_processed\n",
    "\n",
    "print(f\"\\nTotal images processed: {total_processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the data loading pipeline\n",
    "if total_processed > 0:\n",
    "    print(\"Testing data loading pipeline...\")\n",
    "    \n",
    "    # Initialize preprocessor\n",
    "    preprocessor = DataPreprocessor(config_path)\n",
    "    \n",
    "    try:\n",
    "        # Create data loaders\n",
    "        train_loader, val_loader, test_loader = preprocessor.create_dataloaders(\n",
    "            os.path.join(processed_dir, 'train'),\n",
    "            os.path.join(processed_dir, 'val'),\n",
    "            os.path.join(processed_dir, 'test')\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Data loaders created successfully!\")\n",
    "        print(f\"  Train batches: {len(train_loader)}\")\n",
    "        print(f\"  Val batches: {len(val_loader)}\")\n",
    "        if test_loader:\n",
    "            print(f\"  Test batches: {len(test_loader)}\")\n",
    "        \n",
    "        # Test loading a batch\n",
    "        print(\"\\nTesting batch loading...\")\n",
    "        for L, AB, filenames in train_loader:\n",
    "            print(f\"✓ Successfully loaded batch:\")\n",
    "            print(f\"  L channel shape: {L.shape}\")\n",
    "            print(f\"  AB channels shape: {AB.shape}\")\n",
    "            print(f\"  Batch size: {len(filenames)}\")\n",
    "            print(f\"  Sample filenames: {filenames[:3]}\")\n",
    "            \n",
    "            # Check value ranges\n",
    "            print(f\"  L channel range: [{L.min():.3f}, {L.max():.3f}]\")\n",
    "            print(f\"  AB channels range: [{AB.min():.3f}, {AB.max():.3f}]\")\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating data loaders: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No processed images available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize processed data samples\n",
    "if total_processed > 0 and 'train_loader' in locals():\n",
    "    print(\"Visualizing processed data samples...\")\n",
    "    \n",
    "    # Get a batch of data\n",
    "    for L, AB, filenames in train_loader:\n",
    "        # Take first 4 samples from batch\n",
    "        num_samples = min(4, L.shape[0])\n",
    "        \n",
    "        fig, axes = plt.subplots(3, num_samples, figsize=(15, 12))\n",
    "        if num_samples == 1:\n",
    "            axes = axes.reshape(3, 1)\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Convert back to RGB for visualization\n",
    "            rgb_image = preprocessor.lab_to_rgb(\n",
    "                L[i:i+1], AB[i:i+1]\n",
    "            )[0]\n",
    "            \n",
    "            # Denormalize L channel for display\n",
    "            L_display = (L[i, 0].numpy() + 1) / 2  # -1,1 -> 0,1\n",
    "            \n",
    "            # Original RGB\n",
    "            axes[0, i].imshow(rgb_image)\n",
    "            axes[0, i].set_title(f'Original\\n{filenames[i][:15]}...')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # L channel (model input)\n",
    "            axes[1, i].imshow(L_display, cmap='gray')\n",
    "            axes[1, i].set_title('L Channel (Input)')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            # AB channels visualization\n",
    "            AB_display = AB[i].numpy().transpose(1, 2, 0)  # CHW -> HWC\n",
    "            # Normalize AB for display\n",
    "            AB_norm = (AB_display + 1) / 2  # -1,1 -> 0,1\n",
    "            axes[2, i].imshow(AB_norm[:, :, :2])  # Show both A and B as RGB-like\n",
    "            axes[2, i].set_title('AB Channels (Target)')\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break\n",
    "        \n",
    "else:\n",
    "    print(\"No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processing summary\n",
    "summary = {\n",
    "    'preprocessing_completed': True,\n",
    "    'target_size': target_size,\n",
    "    'color_space': config['data']['color_space'],\n",
    "    'processed_counts': {\n",
    "        'train': count_images(os.path.join(processed_dir, 'train')),\n",
    "        'val': count_images(os.path.join(processed_dir, 'val')),\n",
    "        'test': count_images(os.path.join(processed_dir, 'test'))\n",
    "    },\n",
    "    'total_processed': total_processed,\n",
    "    'data_splits': {\n",
    "        'train_ratio': config['data']['train_split'],\n",
    "        'val_ratio': config['data']['val_split'],\n",
    "        'test_ratio': config['data']['test_split']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = os.path.join(processed_dir, 'preprocessing_summary.yaml')\n",
    "with open(summary_path, 'w') as f:\n",
    "    yaml.dump(summary, f, default_flow_style=False)\n",
    "\n",
    "print(\"Preprocessing Summary:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for subkey, subvalue in value.items():\n",
    "            print(f\"  {subkey}: {subvalue}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nSummary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Your data has been preprocessed and is ready for training!\n",
    "\n",
    "**What was done:**\n",
    "1. ✅ Images resized to consistent size\n",
    "2. ✅ RGB images converted to LAB color space\n",
    "3. ✅ L channel prepared as model input (grayscale)\n",
    "4. ✅ AB channels prepared as model target (color information)\n",
    "5. ✅ Data loaders tested and working\n",
    "\n",
    "**Next notebooks to run:**\n",
    "1. `03_augmentation_experiments.ipynb` - Test different augmentation strategies\n",
    "2. `04_model_training_baseline.ipynb` - Train baseline model without augmentation\n",
    "3. `05_model_training_augmented.ipynb` - Train with data augmentation\n",
    "4. `06_evaluation_comparison.ipynb` - Compare model performance\n",
    "\n",
    "**Ready for training!** 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
