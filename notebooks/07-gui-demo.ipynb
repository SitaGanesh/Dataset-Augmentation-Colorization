{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Demo and Interactive Testing\n",
    "\n",
    "This notebook demonstrates how to use the GUI application and provides interactive testing of your trained models.\n",
    "\n",
    "## Objectives:\n",
    "- Launch and test the GUI application\n",
    "- Load and test both baseline and augmented models\n",
    "- Interactive colorization of user images\n",
    "- Performance testing and user experience evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageTk\n",
    "import yaml\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from model_architecture import create_model\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from evaluation import ColorizationEvaluator\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check if we're in a GUI environment\n",
    "try:\n",
    "    import tkinter as tk\n",
    "    test_root = tk.Tk()\n",
    "    test_root.withdraw()  # Hide the test window\n",
    "    test_root.destroy()\n",
    "    gui_available = True\n",
    "    print(\"‚úÖ GUI environment available\")\n",
    "except Exception as e:\n",
    "    gui_available = False\n",
    "    print(f\"‚ö†Ô∏è GUI environment not available: {e}\")\n",
    "    print(\"   Running in headless mode - GUI demo will be limited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Check Model Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../config/config.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Setup directories\n",
    "baseline_model_dir = \"../models/baseline_model\"\n",
    "augmented_model_dir = \"../models/augmented_model\"\n",
    "gui_demo_results = \"../results/gui_demo\"\n",
    "\n",
    "os.makedirs(gui_demo_results, exist_ok=True)\n",
    "\n",
    "print(f\"GUI demo results will be saved to: {gui_demo_results}\")\n",
    "\n",
    "# Check for trained models\n",
    "baseline_model_path = os.path.join(baseline_model_dir, \"baseline_model_complete.pth\")\n",
    "augmented_model_path = os.path.join(augmented_model_dir, \"augmented_model_complete.pth\")\n",
    "baseline_weights_path = os.path.join(baseline_model_dir, \"baseline_weights.pth\")\n",
    "augmented_weights_path = os.path.join(augmented_model_dir, \"augmented_weights.pth\")\n",
    "\n",
    "print(f\"\\nModel Availability Check:\")\n",
    "print(f\"=\" * 30)\n",
    "\n",
    "baseline_available = False\n",
    "augmented_available = False\n",
    "\n",
    "if os.path.exists(baseline_model_path) or os.path.exists(baseline_weights_path):\n",
    "    baseline_available = True\n",
    "    print(f\"‚úÖ Baseline model found\")\n",
    "    if os.path.exists(baseline_model_path):\n",
    "        print(f\"   Complete model: {baseline_model_path}\")\n",
    "    if os.path.exists(baseline_weights_path):\n",
    "        print(f\"   Weights only: {baseline_weights_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Baseline model not found\")\n",
    "    print(f\"   Expected: {baseline_model_path}\")\n",
    "    print(f\"   Or: {baseline_weights_path}\")\n",
    "\n",
    "if os.path.exists(augmented_model_path) or os.path.exists(augmented_weights_path):\n",
    "    augmented_available = True\n",
    "    print(f\"\\n‚úÖ Augmented model found\")\n",
    "    if os.path.exists(augmented_model_path):\n",
    "        print(f\"   Complete model: {augmented_model_path}\")\n",
    "    if os.path.exists(augmented_weights_path):\n",
    "        print(f\"   Weights only: {augmented_weights_path}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Augmented model not found\")\n",
    "    print(f\"   Expected: {augmented_model_path}\")\n",
    "    print(f\"   Or: {augmented_weights_path}\")\n",
    "\n",
    "if not baseline_available and not augmented_available:\n",
    "    print(f\"\\n‚ö†Ô∏è No trained models found!\")\n",
    "    print(f\"Please train models using notebooks 04 and 05 first.\")\n",
    "    print(f\"Or check if models are saved in the correct location.\")\n",
    "else:\n",
    "    print(f\"\\nüéâ Ready for GUI testing with available models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Model Loading (Non-GUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading models programmatically before GUI\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "baseline_model = None\n",
    "augmented_model = None\n",
    "\n",
    "# Test baseline model loading\n",
    "if baseline_available:\n",
    "    print(f\"\\nTesting baseline model loading...\")\n",
    "    try:\n",
    "        baseline_model = create_model(config_path)\n",
    "        \n",
    "        # Load weights\n",
    "        if os.path.exists(baseline_model_path):\n",
    "            checkpoint = torch.load(baseline_model_path, map_location=device)\n",
    "            baseline_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            baseline_model.load_state_dict(torch.load(baseline_weights_path, map_location=device))\n",
    "        \n",
    "        baseline_model = baseline_model.to(device)\n",
    "        baseline_model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Baseline model loaded successfully\")\n",
    "        print(f\"   Parameters: {baseline_model.count_parameters():,}\")\n",
    "        print(f\"   Size: {baseline_model.get_model_size():.2f} MB\")\n",
    "        \n",
    "        # Test inference\n",
    "        test_input = torch.randn(1, 1, *config['data']['input_size']).to(device)\n",
    "        with torch.no_grad():\n",
    "            test_output = baseline_model(test_input)\n",
    "        print(f\"   Test inference: ‚úÖ Output shape {test_output.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading baseline model: {e}\")\n",
    "        baseline_model = None\n",
    "\n",
    "# Test augmented model loading\n",
    "if augmented_available:\n",
    "    print(f\"\\nTesting augmented model loading...\")\n",
    "    try:\n",
    "        augmented_model = create_model(config_path)\n",
    "        \n",
    "        # Load weights\n",
    "        if os.path.exists(augmented_model_path):\n",
    "            checkpoint = torch.load(augmented_model_path, map_location=device)\n",
    "            augmented_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            augmented_model.load_state_dict(torch.load(augmented_weights_path, map_location=device))\n",
    "        \n",
    "        augmented_model = augmented_model.to(device)\n",
    "        augmented_model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Augmented model loaded successfully\")\n",
    "        print(f\"   Parameters: {augmented_model.count_parameters():,}\")\n",
    "        print(f\"   Size: {augmented_model.get_model_size():.2f} MB\")\n",
    "        \n",
    "        # Test inference\n",
    "        test_input = torch.randn(1, 1, *config['data']['input_size']).to(device)\n",
    "        with torch.no_grad():\n",
    "            test_output = augmented_model(test_input)\n",
    "        print(f\"   Test inference: ‚úÖ Output shape {test_output.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading augmented model: {e}\")\n",
    "        augmented_model = None\n",
    "\n",
    "print(f\"\\nüìä Model Loading Summary:\")\n",
    "print(f\"  Baseline model: {'‚úÖ Loaded' if baseline_model else '‚ùå Failed'}\")\n",
    "print(f\"  Augmented model: {'‚úÖ Loaded' if augmented_model else '‚ùå Failed'}\")\n",
    "\n",
    "if baseline_model or augmented_model:\n",
    "    print(f\"\\nüéØ Ready for interactive testing!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è No models loaded successfully - GUI will have limited functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Launch GUI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the GUI application\n",
    "if gui_available and (baseline_model or augmented_model):\n",
    "    print(\"Launching GUI application...\")\n",
    "    print(\"Note: The GUI will open in a separate window.\")\n",
    "    print(\"Close this cell or interrupt the kernel to stop the GUI.\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GUI INSTRUCTIONS:\")\n",
    "    print(\"1. Click 'Load Image' to select a color image\")\n",
    "    print(\"2. Select a model from the dropdown menu\")\n",
    "    print(\"3. Click 'Colorize' to process the image\")\n",
    "    print(\"4. Click 'Save Result' to save the colorized image\")\n",
    "    print(\"5. Try different images and compare models!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Launch GUI in a separate thread to keep notebook interactive\n",
    "        def launch_gui():\n",
    "            try:\n",
    "                from src.gui import main\n",
    "                main()  # This will block until GUI is closed\n",
    "            except Exception as e:\n",
    "                print(f\"Error launching GUI: {e}\")\n",
    "        \n",
    "        # Start GUI in background thread\n",
    "        gui_thread = threading.Thread(target=launch_gui, daemon=True)\n",
    "        gui_thread.start()\n",
    "        \n",
    "        print(\"\\nüñ•Ô∏è GUI application started!\")\n",
    "        print(\"If the GUI window doesn't appear, check:\")\n",
    "        print(\"  - Your display is properly configured\")\n",
    "        print(\"  - CustomTkinter is installed (pip install customtkinter)\")\n",
    "        print(\"  - No firewall blocking the application\")\n",
    "        \n",
    "        # Wait a bit to see if GUI starts successfully\n",
    "        time.sleep(3)\n",
    "        \n",
    "        if gui_thread.is_alive():\n",
    "            print(\"\\n‚úÖ GUI is running successfully!\")\n",
    "            print(\"Switch to the GUI window to start colorizing images.\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå GUI may have encountered an error.\")\n",
    "            print(\"Check the output above for error messages.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error launching GUI: {e}\")\n",
    "        print(\"\\nFallback: Try running the GUI from command line:\")\n",
    "        print(\"python src/gui.py\")\n",
    "\n",
    "elif not gui_available:\n",
    "    print(\"‚ö†Ô∏è GUI not available in this environment\")\n",
    "    print(\"This is common in:\")\n",
    "    print(\"  - Headless servers\")\n",
    "    print(\"  - Docker containers without X11 forwarding\")\n",
    "    print(\"  - Some cloud notebook environments\")\n",
    "    print(\"\\nAlternatives:\")\n",
    "    print(\"  1. Run locally: python src/gui.py\")\n",
    "    print(\"  2. Use programmatic testing below\")\n",
    "    print(\"  3. Set up X11 forwarding if on remote server\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No trained models available for GUI testing\")\n",
    "    print(\"Please train models first using notebooks 04 and 05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Programmatic Testing (Alternative to GUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatic testing for environments without GUI\n",
    "print(\"Programmatic Testing of Models\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for test images\n",
    "test_image_dir = \"../data/processed/val\"  # Use validation images for testing\n",
    "test_images = []\n",
    "\n",
    "if os.path.exists(test_image_dir):\n",
    "    test_images = [f for f in os.listdir(test_image_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    test_images = test_images[:3]  # Limit to first 3 images\n",
    "    print(f\"Found {len(test_images)} test images in {test_image_dir}\")\n",
    "else:\n",
    "    print(f\"No test images found in {test_image_dir}\")\n",
    "\n",
    "if test_images and (baseline_model or augmented_model):\n",
    "    print(f\"\\nTesting colorization on sample images...\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize preprocessor and evaluator\n",
    "        preprocessor = DataPreprocessor(config_path)\n",
    "        evaluator = ColorizationEvaluator(config_path)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, img_filename in enumerate(test_images):\n",
    "            print(f\"\\nProcessing image {i+1}: {img_filename}\")\n",
    "            \n",
    "            # Load and preprocess image\n",
    "            img_path = os.path.join(test_image_dir, img_filename)\n",
    "            \n",
    "            try:\n",
    "                # Load image\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image = image.resize(tuple(config['data']['input_size']), Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Convert to LAB and prepare tensors\n",
    "                from skimage import color\n",
    "                image_np = np.array(image)\n",
    "                lab_image = color.rgb2lab(image_np).astype(np.float32)\n",
    "                \n",
    "                # Extract L channel and normalize\n",
    "                L = lab_image[:, :, 0] / 100.0  # 0-100 -> 0-1\n",
    "                L = (L - 0.5) / 0.5  # 0-1 -> -1,1\n",
    "                L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).to(device)\n",
    "                \n",
    "                # True AB channels for comparison\n",
    "                AB_true = lab_image[:, :, 1:] / 128.0  # Normalize AB channels\n",
    "                AB_true = np.transpose(AB_true, (2, 0, 1))  # HWC -> CHW\n",
    "                AB_true_tensor = torch.from_numpy(AB_true).unsqueeze(0)\n",
    "                \n",
    "                result = {\n",
    "                    'filename': img_filename,\n",
    "                    'original_rgb': image_np / 255.0,\n",
    "                    'input_L': (L + 1) / 2  # For display\n",
    "                }\n",
    "                \n",
    "                # Test baseline model\n",
    "                if baseline_model:\n",
    "                    with torch.no_grad():\n",
    "                        AB_pred_baseline = baseline_model(L_tensor).cpu()\n",
    "                        \n",
    "                    # Convert back to RGB\n",
    "                    rgb_baseline = evaluator.lab_to_rgb(L_tensor.cpu(), AB_pred_baseline)[0]\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    psnr_baseline = evaluator.calculate_psnr(rgb_baseline, result['original_rgb'])\n",
    "                    ssim_baseline = evaluator.calculate_ssim(rgb_baseline, result['original_rgb'])\n",
    "                    \n",
    "                    result['baseline'] = {\n",
    "                        'rgb': rgb_baseline,\n",
    "                        'psnr': psnr_baseline,\n",
    "                        'ssim': ssim_baseline\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  Baseline - PSNR: {psnr_baseline:.2f} dB, SSIM: {ssim_baseline:.4f}\")\n",
    "                \n",
    "                # Test augmented model\n",
    "                if augmented_model:\n",
    "                    with torch.no_grad():\n",
    "                        AB_pred_augmented = augmented_model(L_tensor).cpu()\n",
    "                        \n",
    "                    # Convert back to RGB\n",
    "                    rgb_augmented = evaluator.lab_to_rgb(L_tensor.cpu(), AB_pred_augmented)[0]\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    psnr_augmented = evaluator.calculate_psnr(rgb_augmented, result['original_rgb'])\n",
    "                    ssim_augmented = evaluator.calculate_ssim(rgb_augmented, result['original_rgb'])\n",
    "                    \n",
    "                    result['augmented'] = {\n",
    "                        'rgb': rgb_augmented,\n",
    "                        'psnr': psnr_augmented,\n",
    "                        'ssim': ssim_augmented\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  Augmented - PSNR: {psnr_augmented:.2f} dB, SSIM: {ssim_augmented:.4f}\")\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error processing {img_filename}: {e}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Processed {len(results)} images successfully\")\n",
    "        \n",
    "        # Save results for later use\n",
    "        import pickle\n",
    "        results_path = os.path.join(gui_demo_results, 'programmatic_test_results.pkl')\n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        print(f\"Results saved to: {results_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in programmatic testing: {e}\")\n",
    "        results = []\n",
    "\n",
    "else:\n",
    "    print(\"\\nProgrammatic testing skipped - no test images or models available\")\n",
    "    results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Programmatic Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results from programmatic testing\n",
    "if 'results' in locals() and len(results) > 0:\n",
    "    print(\"Visualizing programmatic test results...\")\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\nVisualizing result {i+1}: {result['filename']}\")\n",
    "        \n",
    "        # Determine how many models we have\n",
    "        has_baseline = 'baseline' in result\n",
    "        has_augmented = 'augmented' in result\n",
    "        \n",
    "        # Calculate subplot layout\n",
    "        num_cols = 2 + has_baseline + has_augmented\n",
    "        fig, axes = plt.subplots(1, num_cols, figsize=(4*num_cols, 4))\n",
    "        \n",
    "        if num_cols == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        col_idx = 0\n",
    "        \n",
    "        # Original image\n",
    "        axes[col_idx].imshow(result['original_rgb'])\n",
    "        axes[col_idx].set_title(f'Original\\n{result[\"filename\"][:20]}...', fontsize=10)\n",
    "        axes[col_idx].axis('off')\n",
    "        col_idx += 1\n",
    "        \n",
    "        # Input (grayscale)\n",
    "        axes[col_idx].imshow(result['input_L'], cmap='gray')\n",
    "        axes[col_idx].set_title('Input (Grayscale)', fontsize=10)\n",
    "        axes[col_idx].axis('off')\n",
    "        col_idx += 1\n",
    "        \n",
    "        # Baseline result\n",
    "        if has_baseline:\n",
    "            axes[col_idx].imshow(result['baseline']['rgb'])\n",
    "            axes[col_idx].set_title(\n",
    "                f'Baseline\\nPSNR: {result[\"baseline\"][\"psnr\"]:.1f} dB\\nSSIM: {result[\"baseline\"][\"ssim\"]:.3f}', \n",
    "                fontsize=10\n",
    "            )\n",
    "            axes[col_idx].axis('off')\n",
    "            col_idx += 1\n",
    "        \n",
    "        # Augmented result\n",
    "        if has_augmented:\n",
    "            axes[col_idx].imshow(result['augmented']['rgb'])\n",
    "            axes[col_idx].set_title(\n",
    "                f'Augmented\\nPSNR: {result[\"augmented\"][\"psnr\"]:.1f} dB\\nSSIM: {result[\"augmented\"][\"ssim\"]:.3f}', \n",
    "                fontsize=10\n",
    "            )\n",
    "            axes[col_idx].axis('off')\n",
    "            col_idx += 1\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save individual result\n",
    "        result_path = os.path.join(gui_demo_results, f'test_result_{i+1}.png')\n",
    "        plt.savefig(result_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  Saved to: {result_path}\")\n",
    "        \n",
    "        # Print comparison if both models available\n",
    "        if has_baseline and has_augmented:\n",
    "            psnr_diff = result['augmented']['psnr'] - result['baseline']['psnr']\n",
    "            ssim_diff = result['augmented']['ssim'] - result['baseline']['ssim']\n",
    "            \n",
    "            print(f\"  Model Comparison:\")\n",
    "            print(f\"    PSNR improvement: {psnr_diff:+.2f} dB\")\n",
    "            print(f\"    SSIM improvement: {ssim_diff:+.4f}\")\n",
    "            \n",
    "            if psnr_diff > 0 and ssim_diff > 0:\n",
    "                print(f\"    Result: ‚úÖ Augmented model performed better\")\n",
    "            elif psnr_diff < 0 and ssim_diff < 0:\n",
    "                print(f\"    Result: ‚ùå Baseline model performed better\")\n",
    "            else:\n",
    "                print(f\"    Result: ‚ûñ Mixed results - models performed similarly\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    if len(results) > 1 and has_baseline and has_augmented:\n",
    "        print(f\"\\nüìä OVERALL STATISTICS ({len(results)} images):\")\n",
    "        print(f\"=\" * 50)\n",
    "        \n",
    "        baseline_psnrs = [r['baseline']['psnr'] for r in results]\n",
    "        augmented_psnrs = [r['augmented']['psnr'] for r in results]\n",
    "        baseline_ssims = [r['baseline']['ssim'] for r in results]\n",
    "        augmented_ssims = [r['augmented']['ssim'] for r in results]\n",
    "        \n",
    "        avg_psnr_baseline = np.mean(baseline_psnrs)\n",
    "        avg_psnr_augmented = np.mean(augmented_psnrs)\n",
    "        avg_ssim_baseline = np.mean(baseline_ssims)\n",
    "        avg_ssim_augmented = np.mean(augmented_ssims)\n",
    "        \n",
    "        psnr_improvement = avg_psnr_augmented - avg_psnr_baseline\n",
    "        ssim_improvement = avg_ssim_augmented - avg_ssim_baseline\n",
    "        \n",
    "        print(f\"Average PSNR:\")\n",
    "        print(f\"  Baseline: {avg_psnr_baseline:.2f} dB\")\n",
    "        print(f\"  Augmented: {avg_psnr_augmented:.2f} dB\")\n",
    "        print(f\"  Improvement: {psnr_improvement:+.2f} dB\")\n",
    "        \n",
    "        print(f\"\\nAverage SSIM:\")\n",
    "        print(f\"  Baseline: {avg_ssim_baseline:.4f}\")\n",
    "        print(f\"  Augmented: {avg_ssim_augmented:.4f}\")\n",
    "        print(f\"  Improvement: {ssim_improvement:+.4f}\")\n",
    "        \n",
    "        # Count wins\n",
    "        augmented_wins = sum(1 for r in results \n",
    "                           if r['augmented']['psnr'] > r['baseline']['psnr'] \n",
    "                           and r['augmented']['ssim'] > r['baseline']['ssim'])\n",
    "        \n",
    "        print(f\"\\nModel Comparison:\")\n",
    "        print(f\"  Augmented wins: {augmented_wins}/{len(results)} images\")\n",
    "        print(f\"  Win rate: {augmented_wins/len(results)*100:.1f}%\")\n",
    "        \n",
    "        if augmented_wins > len(results) / 2:\n",
    "            print(f\"  üèÜ Augmented model is generally better\")\n",
    "        else:\n",
    "            print(f\"  üèÜ Baseline model is competitive\")\n",
    "\n",
    "else:\n",
    "    print(\"No programmatic test results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking of the models\n",
    "if baseline_model or augmented_model:\n",
    "    print(\"Performance Benchmarking\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Test different batch sizes and input sizes\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
